{"cells":[{"cell_type":"markdown","id":"2ae53c3b","metadata":{"id":"2ae53c3b"},"source":["---"]},{"cell_type":"markdown","id":"1ac376f4","metadata":{"id":"1ac376f4"},"source":["# Introdução e Classificação Simples\n","\n","Neste laboratório você irá realizar algumas operações básicas com imagens (leitura e manipulações); você programará um classificador entre cães e gatos manualmente; e, você também usará o framework do FastAI para treinar uma rede neural profunda nesse mesmo problema.\n","\n","Além das questões avaliadas, acrescentamos também um problema que nos deparamos a fazer a aula e que não tivemos tempo de resolver: o problema do blend dos canais de cores das 3 imagens da capivara no Google Slides."]},{"cell_type":"code","execution_count":null,"id":"a16165ea","metadata":{"id":"a16165ea"},"outputs":[],"source":["# from pathlib import Path             # Já importado pelo fastai\n","# from typing import Callable          # Já importado pelo fastai\n","# import numpy as np                   # Já importado pelo fastai\n","# import pandas as pd                  # Já importado pelo fastai\n","# from PIL import Image                # Já importado pelo fastai\n","# from matplotlib import pyplot as plt # Já importado pelo fastai\n","from fastai.vision.all import *\n","import cv2\n","\n","\n","\n","# Caso esteja executando o notebook localmente, reimplementa o cv2_imshow\n","from IPython.utils import io\n","from IPython.display import display\n","import warnings\n","try:\n","    from google.colab.patches import cv2_imshow\n","except:\n","    def cv2_imshow(img):\n","        display(Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))\n","\n","# Faz o numpy imprimir mais números por linha\n","np.set_printoptions(edgeitems=40, linewidth=130)"]},{"cell_type":"code","execution_count":null,"id":"d0195053","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"41d6791b11405d79e03fc9df89d6976a","grade":false,"grade_id":"dataset","locked":true,"schema_version":3,"solution":false,"task":false},"id":"d0195053"},"outputs":[],"source":["# Verifica se já foram baixadas as imagens do drive, baixando-as e descompactando se necessário\n","! [ ! -d \"/content/cats_vs_dogs\" ] && gdown -O /content/cats_vs_dogs.zip \"1VuxwfbLZDXPt_0yKTauh4LRIhqMX1SdR\" &&  unzip -q /content/cats_vs_dogs.zip -d /content && rm /content/cats_vs_dogs.zip\n","\n","base_path = Path(\"/content/cats_vs_dogs\")"]},{"cell_type":"markdown","id":"9252f42a","metadata":{"id":"9252f42a"},"source":["## Operações Básicas"]},{"cell_type":"markdown","id":"31365298","metadata":{"id":"31365298"},"source":["### Leitura e Visualização de uma imagem (apenas ilustrativo)"]},{"cell_type":"markdown","id":"d60d9848","metadata":{"id":"d60d9848"},"source":["Vamos carregar algumas imagens aqui, fique livre para escolher qualquer imagem:\n","\n","(escolhemos filhotes por serem mais ditáticos ...)"]},{"cell_type":"code","source":["caminho_imagem_cat = str(base_path/'train'/'cat'/'00125.jpg')\n","caminho_imagem_dog = str(base_path/'train'/'dog'/'00042.jpg')\n","caminho_imagem_cat, caminho_imagem_dog"],"metadata":{"id":"PD73_M75R0zp"},"id":"PD73_M75R0zp","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"9a43c04b","metadata":{"id":"9a43c04b"},"source":["Vamos carregar uma imagem usando o Pillow, por meio da função `Image.open`:"]},{"cell_type":"code","source":["img_pillow = Image.open(caminho_imagem_cat)\n","img_pillow"],"metadata":{"id":"_wjcfoQPR4ZT"},"id":"_wjcfoQPR4ZT","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"4fb2c871","metadata":{"id":"4fb2c871"},"source":["A imagem Pillow é um objeto próprio dela, mas pode ser convertido para uma matriz numpy por meio do casting `np.array(img_pillow)`"]},{"cell_type":"code","source":["type(img_pillow)"],"metadata":{"id":"fMwKk_XDR8Co"},"id":"fMwKk_XDR8Co","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"307472fd","metadata":{"id":"307472fd"},"source":["Vamos carregar uma imagem usando o OpenCV, para isso usamos a função `cv2.imread`. Já para exibi-la, no Colab usamos o cv2_imshow (mas no notebook local acaba sendo o próprio PIL):\n","\n","Perceba também que o tipo da imagem que o OpenCV retorna já é uma matriz numpy (`numpy.ndarray`)"]},{"cell_type":"code","source":["img_opencv = cv2.imread(caminho_imagem_dog)\n","cv2_imshow(img_opencv)\n","type(img_opencv)"],"metadata":{"id":"tj9hEe2HSIYH"},"id":"tj9hEe2HSIYH","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"72411f88","metadata":{"id":"72411f88"},"source":["Vamos observar os pixels da Imagem no formato de tabela (planilha), vamos carregar uma imagem de um gato menor (subamostrada e só com um canal).\n","\n","Perceba que a subamostragem foi realizado da forma mais rápida (bronca) possível: usando stepping `::2`. Em vez de calcular a média do 2x2 pixels, nós só pegamos o valor de 1 que está no topo esquerdo desse 2x2, isso é, começando do índice zero e pegando o próximo a 2 (índices pares).\n","\n","Vamos usar a biblioteca Pandas, para fazer uma exibição tipo planilha."]},{"cell_type":"code","source":["pequeno_gato = cv2.imread(str(base_path/'train'/'cat'/'00216.jpg'))[::2, ::2, 1]\n","cv2_imshow(pequeno_gato)\n","df = pd.DataFrame(pequeno_gato)\n","df.style.set_properties(**{'font-size':'7pt'}).background_gradient('gray', axis=None, vmin=0, vmax=255)"],"metadata":{"id":"3CqHp1BmSiK4"},"id":"3CqHp1BmSiK4","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"10e2919c","metadata":{"id":"10e2919c"},"source":["Vamos ver a imagem no formato de 'função' matemática, nesse plot de grids acaba sendo uma simples função que interpola linearmente os pontos:"]},{"cell_type":"code","source":["image_array = pequeno_gato.astype('float64')\n","\n","x = np.arange(image_array.shape[1])\n","y = np.arange(image_array.shape[0])\n","x, y = np.meshgrid(x, y)\n","fig = plt.figure()\n","ax = fig.add_subplot(111, projection='3d')\n","ax.plot_surface(y, x, image_array, cmap='gray', rcount=image_array.shape[0], ccount=image_array.shape[1])\n","ax.set_xlabel('Y')\n","ax.set_ylabel('X')\n","ax.set_zlabel('Valor')\n","ax.set_zlim(0, 800) # MUDE ISSO PARA VER A ESCALA\n","\n","# MUDE ISSO PARA VER DE OUTRO ANGULO\n","ax.view_init(50, 0)\n","\n","plt.show() # Exibe o plot"],"metadata":{"id":"6v28dQanSnh3"},"id":"6v28dQanSnh3","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"8b50b818","metadata":{"id":"8b50b818"},"source":["Olha o que acontece quando trocamos o formato do OpenCV (BGR) pelo o do Pillow (RGB):"]},{"cell_type":"code","source":["cv2_imshow(np.array(img_pillow))"],"metadata":{"id":"q8XBCpBrS1fQ"},"id":"q8XBCpBrS1fQ","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"4bd947b5","metadata":{"id":"4bd947b5"},"source":["O Matplotlib também tem a mesma convenção do RGB que o Pillow, e usa a função `imshow`:"]},{"cell_type":"code","source":["plt.figure()\n","plt.imshow(img_opencv)"],"metadata":{"id":"5HVsox3WS5iI"},"id":"5HVsox3WS5iI","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"9e6b2a2e","metadata":{"id":"9e6b2a2e"},"source":["Enquanto o Pillow, dentro do Jupyter notebook, mostra a imagem na sua resolução original (e em um formato PNG), o Matplotlib altera a resolução da imagem de acordo com a resolução (DPI) do plot, realizando um redimensionamento contínuo da imagem.\n","\n","Veja inclusive que ele coloca uma escala de `x` e `y` em pixels, e trata a imagem como se fosse uma função."]},{"cell_type":"markdown","id":"3b6508b4","metadata":{"id":"3b6508b4"},"source":["### Converter entre BGR e RGB"]},{"cell_type":"markdown","id":"d3105e08","metadata":{"id":"d3105e08"},"source":["**Explicação sobre o assunto**\n","\n","Então você deve ter percebido que trocar o canal vermelho pelo azul, deixa a imagem com uma percepção de cor completamente diferente. A cor da pele das pessoas tende a ficar azul, mas em certas imagens também pode ser pouco perceptível que as cores estão trocadas, então tem que ficar atento no próprio código!"]},{"cell_type":"code","source":["def converte_BGR_RGB(imagem: np.ndarray):\n","    \"\"\" Recebe uma imagem no formato BGR ou RGB e converte para o outro formato.\n","    :param imagem: imagem com shape (H, W, 3) d\n","    Retorna uma nova imagem convertida (não é para modificar a imagem original).\n","    \"\"\"\n","\n","    imagem_convertida = imagem[:,:, [2, 1, 0]]\n","    return imagem_convertida"],"metadata":{"id":"h0UyhmNcTKex"},"id":"h0UyhmNcTKex","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"6b7dc68b","metadata":{"id":"6b7dc68b"},"source":["Veja, agora a cor deve ficar correta:"]},{"cell_type":"code","source":["plt.imshow(converte_BGR_RGB(img_opencv))"],"metadata":{"id":"jD-2doThTTE3"},"id":"jD-2doThTTE3","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"1c6b0d44","metadata":{"id":"1c6b0d44"},"source":["### Converter de RGB para *grayscale*"]},{"cell_type":"markdown","id":"501c1df9","metadata":{"id":"501c1df9"},"source":["**Explicação sobre o assunto**\n","\n","Para cada pixel da imagem $I(y, x)$ formada pelos canais azul $B(y, x)$, verde $G(y, x)$ e vermelho $R(y, x)$, na convenção do OpenCV $I(y, x) = \\left(B(y, x), G(y, x), R(y, x)\\right)$ aplicamos uma transformação linear a cada um desses canais para obter um novo canal de cinza $C(y, x)$. Essa transformação é aplicada a cada pixel $(y, x)$ da imagem:\n","\n","$C(y, x) = 0.114 B(y, x) + 0.587G(y, x) + 0.299R(y, x)$.\n","\n","Esses coeficientes dependem da sensibilidade do sensor e do meio de exibição (tela) de acordo com a percepção humana. Os coeficientes acimas são para imagens digitais de acordo com a especificação ITU BT.601.\n","\n","Nota: essa transformação só vale para espaços lineares, quando os valores de cada pixel da imagem não está representada como um resultado de uma exponenciação pelo coeficiente gama $\\gamma$: $I_\\text{não linear}(y, x) = I(y, x)^\\gamma$. Caso a imagem não esteja representada linearmente, é necessário fazer a tranformação inversa dessa exponenciação por gama.\n","\n","Nos labs vamos sempre assumir que já está no espaço linear (apesar de provavelmente isso não ser verdade, pelo fato de serem imagens de câmeras)."]},{"cell_type":"code","source":["# questao_grayscale\n","\n","def converte_BGR_para_cinza(imagem_BGR: np.ndarray):\n","    \"\"\"\n","    Implemente a sua própria função que converte uma imagem colorida de três canais BGR (blue, green, red) para\n","    escala de Cinza C conforme a equação C(y, x) = 0.114 B(y, x) + 0.587G(y, x) + 0.299R(y, x) aplicada em cada\n","    pixel (y, x).\n","    :param imagem_BGR: Matriz (H, W, 3) que representa a imagem de altura H, largura W e 3 canais de cores BGR\n","    Retorna uma nova imagem resultante (H, W) em escala de cinza no formato de 8-bits positivos.\n","    Utilize truncamento para aproximar o resultado intermediário que seria em ponto flutuante (para correção)\n","    \"\"\"\n","\n","    imagem_cinza = (imagem_BGR[:,:, 0]*0.114+imagem_BGR[:,:, 1]*0.587+imagem_BGR[:,:, 2]*0.299).astype(np.uint8)\n","    return imagem_cinza"],"metadata":{"id":"yzjIa6I6TeDM"},"id":"yzjIa6I6TeDM","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"1a9fc190","metadata":{"id":"1a9fc190"},"source":["Vejamos o resultado em uma imagem:"]},{"cell_type":"code","source":["plt.imshow(converte_BGR_para_cinza(img_opencv), cmap='gray', vmin=0, vmax=255)"],"metadata":{"id":"5SWHaERBTjC9"},"id":"5SWHaERBTjC9","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"e7b6aeef","metadata":{"id":"e7b6aeef"},"source":["Agora você poderia fazer um plot com o matplotlib, sem passar o argumento do `cmap` e achar que a imagem ainda está colorida. Mas não é isso que está acontecendo. Lembra que o matplotlib interpreta a imagem como se fosse uma função matemática? Ele utiliza uma escala de cor (colormap, que lembra um mapa de calor) e associa o valor da função em um ponto a uma cor.\n","\n","O padrão dele (`None`) é o `viridis` que vai do azul escuro ao amarelo claro, na figura anterior usamos o `gray` que vai do preto para o branco, tem também o `Greys` que vai do branco para o pretor e muitas outras escalas de cor, `plasma`, `inferno`, `rainbow` e [muito mais](https://matplotlib.org/stable/tutorials/colors/colormaps.html):"]},{"cell_type":"markdown","id":"d8415c14","metadata":{"id":"d8415c14"},"source":["### Luminosidade Média da imagem"]},{"cell_type":"markdown","id":"87504121","metadata":{"id":"87504121"},"source":["**Explicação sobre o assunto**\n","\n","Uma das features mais simples de se obter de uma imagem é justamente com relação à sua cor, isto é, a cor média de uma imagem inteira, seja sobre em seus canais R, G ou B ou ainda de sua luminosidade Y.\n","\n","Uma intuição sobre isso seria: caso a imagem fosse reduzida a apenas um pixel (você estivesse olhando de muito longe) qual a cor / luminosidade que você enxergaria?"]},{"cell_type":"code","execution_count":null,"id":"2cf0f792","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"148bf2e989575886f341bb19f7f03e2f","grade":false,"grade_id":"questao_luminosidade","locked":false,"schema_version":3,"solution":true,"task":false},"id":"2cf0f792"},"outputs":[],"source":["# questao_luminosidade\n","\n","def luminosidade_media(imagem: np.ndarray):\n","    \"\"\"\n","    :param imagem: Matriz numpy (H, W) ou (H, W, 3) BGR que representa uma imagem\n","    Retorna uma nova imagem convertida (não é para modificar a imagem original).\n","    \"\"\"\n","\n","    if ( len(imagem.shape) == 3): #color\n","      imagem = converte_BGR_para_cinza(imagem)\n","\n","    luminosidade_media = np.mean(imagem[:])\n","    return luminosidade_media"]},{"cell_type":"markdown","id":"9cfaf530","metadata":{"id":"9cfaf530"},"source":["Vejamos a luminosidade média de algumas imagens:"]},{"cell_type":"code","execution_count":null,"id":"2d9b5a37","metadata":{"id":"2d9b5a37"},"outputs":[],"source":["luminosidade_media(img_opencv), luminosidade_media(np.array(img_pillow))"]},{"cell_type":"markdown","id":"d7d92ad6","metadata":{"id":"d7d92ad6"},"source":["### Calcular Histograma"]},{"cell_type":"markdown","id":"04f61395","metadata":{"id":"04f61395"},"source":["**Explicação sobre o assunto**\n","\n","Uma forma interessante de analisar a iluminação é verificar a distribuição dos valores de cada pixel na imagem, isto é, construir um histograma. Geralmente ele é aplicado em cada canal de cores separadamente, ou ainda na imagem em escala de cinza.\n","\n","Isso já é um 'avanço' sobre a cor média de uma imagem, pois no lugar de gerar apenas uma feature (média), geramos uma distribuição de features (256).\n","\n","Assim para construir um histograma, basta contar quantos pixels tem um determinado valor, que no caso das imagens de 8 bits, são valores que estão entre 0 e 255 (inclusive)."]},{"cell_type":"code","execution_count":null,"id":"4189875f","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"51c40318e660c4b16d749b836af0d4f6","grade":false,"grade_id":"questao_histograma","locked":false,"schema_version":3,"solution":true,"task":false},"id":"4189875f"},"outputs":[],"source":["# questao_histograma\n","\n","def distribuicao(imagem_mono: np.ndarray):\n","    \"\"\"\n","    Implemente a sua própria função que realiza a contagem do valor de cada pixel.\n","    :param imagem_mono: Matriz (H, W) imagem de altura H, largura W\n","    Retorna um vetor (v) com a contagem (q) dos valores de intensidade luminosa (i) da imagem v[i] = q.\n","    \"\"\"\n","    contagem = np.zeros(256, dtype=np.uint64)\n","\n","\n","    for i in range(256):\n","      contagem[i] = len(imagem_mono[ imagem_mono == i])\n","\n","    return contagem"]},{"cell_type":"markdown","id":"2ef654bc","metadata":{"id":"2ef654bc"},"source":["Visualizando essa contagem em um gráfico de barras:"]},{"cell_type":"code","execution_count":null,"id":"30cb1c41","metadata":{"id":"30cb1c41"},"outputs":[],"source":["canal_verde = img_opencv[:, :, 1]\n","plt.bar(np.arange(256), distribuicao(canal_verde), width=1)"]},{"cell_type":"markdown","id":"b6ec7985","metadata":{"id":"b6ec7985"},"source":["O matplotlib também já tem uma função `plt.hist` que já realiza automaticamente o cálculo desse histograma (de um vetor unidirecional). Para isso temos que transformar uma matriz em um vetor que é a concatenação das linhas, como se desenrolássemos a sequência de pixels da matrix `matrix.ravel()` ou `.flatten()`. Só atente para colocar a quantidade de bins entre 0 e 255:"]},{"cell_type":"code","execution_count":null,"id":"4aba1b0b","metadata":{"id":"4aba1b0b"},"outputs":[],"source":["n, bins, patches = plt.hist(canal_verde.ravel(), bins=np.arange(256))\n","n[:40] # Olhando o valor dos 40 primeiros elementos que ele conta"]},{"cell_type":"markdown","id":"bf9dc268","metadata":{"id":"bf9dc268"},"source":["Normalmente, os histogramas podem ser normalizados, de forma que o somatório dos valores dos bins seja igual a 1. Dessa forma teríamos uma densidade de probabilidade (no caso discreto é a própria probabilidade de amostrar o valor daquele bin).\n","\n","Histogramas são bons não apenas para visualizar a distribuição da 'cor' dos pixels em uma imagem, mas também podem ser utilizado para visualizar as 'features' de um dataset."]},{"cell_type":"markdown","id":"14c7844e","metadata":{"id":"14c7844e"},"source":["## Classificação Baseada em Regras"]},{"cell_type":"markdown","id":"33bcbe95","metadata":{"id":"33bcbe95"},"source":["**Explicação sobre o assunto**\n","\n","Agora é um dos ápices desse lab, tudo anteriormente foi um aquecimento para chegarmos aqui. Com base nas funções desenvolvidas anteriormente (nem todas) selecione as *features*, isto é, características (uma função matemática dos números) que consiga distinguir entre imagens de gatos e de cachorros para o dataset apresentado. Assim, quando você encontrar essa(s) característica(s) da imagem que sejam diferentes, você consegue escrever uma função classificadora, que vai estimar se a imagem é de gato ou cachorro. No caso, você também vai ter que definir esse valor de limiar de classificação da feature manualmente.\n","\n","Vamos carregar manualmente as primeiras 100 imagens do conjunto de treinamento para gatos e cachorros, além de definir uma função que você pode usar para rodar em todo o dataset de treino / validação (os profs ainda podem ter outro dataset de teste que vocês não tem acesso, mas que vem da mesma distribuição):"]},{"cell_type":"code","execution_count":null,"id":"f0b3f254","metadata":{"id":"f0b3f254"},"outputs":[],"source":["cats = [cv2.imread(str(p)) for p in (base_path/'train'/'cat').glob('000*.jpg')]\n","dogs = [cv2.imread(str(p)) for p in (base_path/'train'/'dog').glob('000*.jpg')]\n","\n","def avalia_classificador(funcao_classificadora: Callable[[np.ndarray], bool], dataset: Path):\n","    cats = [funcao_classificadora(cv2.imread(str(p))) for p in (dataset/'cat').glob('000*.jpg')]\n","    dogs = [not funcao_classificadora(cv2.imread(str(p))) for p in (dataset/'dog').glob('000*.jpg')]\n","    return np.mean(cats + dogs)\n","\n","#avalia_classificador(classificador_classico, base_path/'train') # roda assim"]},{"cell_type":"markdown","id":"e9c119f0","metadata":{"id":"e9c119f0"},"source":["Você também pode visualizar as imagens do dataset para ter um 'feeling' melhor de como fazer o seu classificador manual:"]},{"cell_type":"code","execution_count":null,"id":"0972c6ff","metadata":{"id":"0972c6ff"},"outputs":[],"source":["fig, axs = plt.subplots(4, 10, figsize=(10, 4))\n","for i, ax in enumerate(axs.flat):\n","    ax.imshow(converte_BGR_RGB(dogs[i])) # ou cats\n","    ax.axis('off')\n","plt.show()"]},{"cell_type":"code","source":["fig, axs = plt.subplots(4, 10, figsize=(10, 4))\n","for i, ax in enumerate(axs.flat):\n","    ax.imshow(converte_BGR_RGB(cats[i])) # ou cats\n","    ax.axis('off')\n","plt.show()"],"metadata":{"id":"EFHsYlHqcNbO"},"id":"EFHsYlHqcNbO","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"bb258fea","metadata":{"id":"bb258fea"},"source":["**Enunciado da Questão**\n","\n","Agora implemente a função `classificador_classico` que recebe uma imagem e retorna se é gato ou cachorro. Para passar no teste tem que ter pelo menos 80% de acurária (total) e pelo menos 75% de precisão em cada classe.\n","\n","Para alegria de todos, você pode usar LLM e pesquisas na internet para resolver essa questão. Se usar LLM, por gentileza, escreva os prompts que usou e o modelo para nós podermos aprender também o prompt engineering que você utilizou.\n","\n","<details><summary><b>Dica</b></summary>\n","<p>\n","As questões todas do lab foram preparadas já como dica para essa questão, usa as funções que você implementou e também tem uma história no final do lab que pode motivá-lo. A solução que pensamos e implementamos é extremamente simples.\n","</p>\n","</details>"]},{"cell_type":"code","execution_count":null,"id":"3319f7f0","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"82c6cc0c3689e8a8f81ba8146fcc3e7b","grade":false,"grade_id":"questao_classica","locked":false,"schema_version":3,"solution":true,"task":false},"id":"3319f7f0"},"outputs":[],"source":["# questao_classica\n","\n","def classificador_classico(imagem: np.ndarray):\n","    \"\"\"Classifica se uma imagem é de um gato ou de um cachorro.\n","    :param imagem: Matriz numpy (H, W, 3) que representa uma imagem BGR.\n","    Retorna True se a imagem for de um gato ou False se for de um cachorro.\n","    \"\"\"\n","\n","    i = luminosidade_media(imagem)\n","\n","    return i >= 120 #valor um pouco abaixo da média (dos gatos) para tomada de decisao com forte viés."]},{"cell_type":"markdown","id":"10b916f2","metadata":{"id":"10b916f2"},"source":["Veja como fica a matriz de confusão:"]},{"cell_type":"code","source":["# testa_classica\n","\n","resposta_cat = np.array([classificador_classico(img) for img in cats])\n","resposta_dog = np.array([classificador_classico(img) for img in dogs])\n","\n","precisao_cat = np.mean(resposta_cat)\n","precisao_dog = np.mean(~resposta_dog)\n","acuracia = np.mean(np.concatenate([resposta_cat, ~resposta_dog]))\n","assert precisao_cat > 0.75\n","assert precisao_dog > 0.75\n","assert acuracia > 0.8"],"metadata":{"id":"a1qUMHPCUho1"},"id":"a1qUMHPCUho1","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"2713d8ea","metadata":{"id":"2713d8ea"},"outputs":[],"source":["def cria_matrix_confusao(resposta_cat, resposta_dog):\n","    classificacao_verdadeira = [True]*len(resposta_cat) + [False]*len(resposta_dog)\n","    classificacao_predita = np.concatenate([resposta_cat, resposta_dog])\n","    conf = pd.crosstab(classificacao_verdadeira, classificacao_predita)\n","    conf.index = ['Dog Verdade', 'Cat Verdade']\n","    conf.columns = ['Dog Predito', 'Cat Predito']\n","    return conf\n","m = cria_matrix_confusao(resposta_cat, resposta_dog)\n","m"]},{"cell_type":"code","source":["(m['Dog Predito']['Dog Verdade'] + m['Cat Predito']['Cat Verdade'])/m.sum().sum()"],"metadata":{"id":"vCCsz2fmVTUT"},"id":"vCCsz2fmVTUT","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"c04fff1f","metadata":{"id":"c04fff1f"},"source":["Agora tente baixar algumas imagens de gatos e cachorros e veja como o seu classificador se comporta (ou então veja na pasta `fora_distribuicao`):"]},{"cell_type":"code","execution_count":null,"id":"caf93827","metadata":{"id":"caf93827"},"outputs":[],"source":["m = cria_matrix_confusao(*[np.array([classificador_classico(cv2.imread(str(p)))\n","                          for p in (base_path/'fora_distribuicao'/animal).glob('*.jpg')]) for animal in ['cat', 'dog']])\n","m"]},{"cell_type":"code","execution_count":null,"id":"ef3e58a5","metadata":{"id":"ef3e58a5"},"outputs":[],"source":["(m['Dog Predito']['Dog Verdade'] + m['Cat Predito']['Cat Verdade'])/m.sum().sum()"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"notify_time":"5","toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"424px"},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[{"file_id":"1ZCECGWzd04TQTRbON8U44kyuU5ANTc37","timestamp":1691337119900}]}},"nbformat":4,"nbformat_minor":5}