{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNCULI3MhjxbLzO3OQdbOb7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kCHSSyutdHzH"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n"]},{"cell_type":"code","source":["print(f\"TensorFlow version = {tf.__version__}\\n\")"],"metadata":{"id":"VxBYuPyIddZP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","\n","! [ ! -d \"/content/data\" ] && gdown -O /content/kick-detector.zip \"1FB_i3nP-XLt373hPuPUXzEZaS61zJVA-\" &&  unzip -q /content/kick-detector.zip -d /content && rm /content/kick-detector.zip\n","\n","base_path = Path(\"/content/data\")\n"],"metadata":{"id":"hoHeadordoL4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filename = \"kick.csv\"\n","\n","df = pd.read_csv(str(base_path/filename))\n","\n","index = range(1, len(df['aX']) + 1)\n","\n","plt.rcParams[\"figure.figsize\"] = (20,10)\n","\n","plt.plot(index, df['aX'], 'g.', label='x', linestyle='solid', marker=',')\n","plt.plot(index, df['aY'], 'b.', label='y', linestyle='solid', marker=',')\n","plt.plot(index, df['aZ'], 'r.', label='z', linestyle='solid', marker=',')\n","plt.title(\"Acceleration\")\n","plt.xlabel(\"Sample #\")\n","plt.ylabel(\"Acceleration (G)\")\n","plt.legend()\n","plt.show()\n","\n","plt.plot(index, df['gX'], 'g.', label='x', linestyle='solid', marker=',')\n","plt.plot(index, df['gY'], 'b.', label='y', linestyle='solid', marker=',')\n","plt.plot(index, df['gZ'], 'r.', label='z', linestyle='solid', marker=',')\n","plt.title(\"Gyroscope\")\n","plt.xlabel(\"Sample #\")\n","plt.ylabel(\"Gyroscope (deg/sec)\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"NPPG-7jhdg35"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set a fixed random seed value, for reproducibility, this will allow us to get\n","# the same random numbers each time the notebook is run\n","SEED = 1337\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","\n","# the list of gestures that data is available for\n","GESTURES = [\n","    \"kick\",\n","    \"no-kick\"\n","]\n","\n","SAMPLES_PER_GESTURE = 119\n","\n","NUM_GESTURES = len(GESTURES)\n","\n","# create a one-hot encoded matrix that is used in the output\n","ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n","\n","inputs = []\n","outputs = []"],"metadata":{"id":"N5k5ydxqdmrU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# read each csv file and push an input and output\n","for gesture_index in range(NUM_GESTURES):\n","  gesture = GESTURES[gesture_index]\n","  print(f\"Processing index {gesture_index} for gesture '{gesture}'.\")\n","\n","  output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n","\n","  df = pd.read_csv(\"./data/\" + gesture + \".csv\")\n","\n","  # calculate the number of gesture recordings in the file\n","  num_recordings = int(df.shape[0] / SAMPLES_PER_GESTURE)\n","\n","  print(f\"\\tThere are {num_recordings} recordings of the {gesture} gesture.\")\n","\n","  for i in range(num_recordings):\n","    tensor = []\n","    for j in range(SAMPLES_PER_GESTURE):\n","      index = i * SAMPLES_PER_GESTURE + j\n","      # normalize the input data, between 0 to 1:\n","      # - acceleration is between: -4 to +4\n","      # - gyroscope is between: -2000 to +2000\n","      tensor += [\n","          (df['aX'][index] + 4) / 8,\n","          (df['aY'][index] + 4) / 8,\n","          (df['aZ'][index] + 4) / 8,\n","          (df['gX'][index] + 2000) / 4000,\n","          (df['gY'][index] + 2000) / 4000,\n","          (df['gZ'][index] + 2000) / 4000\n","      ]\n","\n","    inputs.append(tensor)\n","    outputs.append(output)\n","\n","# convert the list to numpy array\n","inputs = np.array(inputs)\n","outputs = np.array(outputs)\n","\n","print(\"Data set parsing and preparation complete.\")\n"],"metadata":{"id":"YwQvR514msIz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_inputs = len(inputs)\n","randomize = np.arange(num_inputs)\n","np.random.shuffle(randomize)\n","\n","# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n","inputs = inputs[randomize]\n","outputs = outputs[randomize]\n","\n","# Split the recordings (group of samples) into three sets: training, testing and validation\n","TRAIN_SPLIT = int(0.6 * num_inputs)\n","TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n","\n","inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n","outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n","\n","print(\"Data set randomization and splitting complete.\")\n"],"metadata":{"id":"334bGCKxnLRe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.Sequential()\n","\n","model.add(tf.keras.layers.Dense(50, activation='relu')) # relu is used for performance\n","model.add(tf.keras.layers.Dense(15, activation='relu'))\n","model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax')) # softmax is used, because we only expect one gesture to occur per input\n","\n","model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n","\n","history = model.fit(inputs_train, outputs_train, epochs=200, batch_size=1, validation_data=(inputs_validate, outputs_validate))\n"],"metadata":{"id":"KXjkYMnEnTf0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.rcParams[\"figure.figsize\"] = (20,10)\n","\n","# graph the loss, the model above is configure to use \"mean squared error\" as the loss function\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(loss) + 1)\n","plt.plot(epochs, loss, 'g.', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","print(plt.rcParams[\"figure.figsize\"])"],"metadata":{"id":"rYs_8J0woG60"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SKIP = 100\n","\n","# graph of mean absolute error\n","mae = history.history['mae']\n","val_mae = history.history['val_mae']\n","plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n","plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n","plt.title('Training and validation mean absolute error')\n","plt.xlabel('Epochs')\n","plt.ylabel('MAE')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"zQXYy1DvoIIx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = model.predict(inputs_test)\n","\n","# print the predictions and the expected ouputs\n","print(\"predictions =\\n\", np.round(predictions, decimals=3))\n","print(\"actual =\\n\", outputs_test)\n"],"metadata":{"id":"6Ydqfn5moMoc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert the model to the TensorFlow Lite format without quantization\n","# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","# tflite_model = converter.convert()\n","\n","# # Save the model to disk\n","# open(\"./content/model/kick_model.tflite\", \"wb\").write(tflite_model)\n","\n","# import os\n","# basic_model_size = os.path.getsize(\"./model/kick_model.tflite\")\n","# print(\"Model is %d bytes\" % basic_model_size)"],"metadata":{"id":"0l_MapzuoVBT"},"execution_count":null,"outputs":[]}]}