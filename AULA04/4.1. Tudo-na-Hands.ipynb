{"cells":[{"cell_type":"markdown","id":"d91166d9","metadata":{"id":"d91166d9"},"source":["---"]},{"cell_type":"markdown","id":"46139365","metadata":{"id":"46139365"},"source":["# Dependências"]},{"cell_type":"code","source":["!sudo apt install tesseract-ocr\n","!pip install pytesseract"],"metadata":{"id":"81AFpng4DtiI"},"id":"81AFpng4DtiI","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"62202089","metadata":{"id":"62202089"},"outputs":[],"source":["import cv2\n","import os\n","import pytesseract\n","import numpy as np\n","import PIL.Image\n","from pathlib import Path\n","from matplotlib import pyplot as plt"]},{"cell_type":"markdown","source":["# Utils"],"metadata":{"id":"DhRqj8cwCYyp"},"id":"DhRqj8cwCYyp"},{"cell_type":"code","source":["def ocr(imagem):\n","    return pytesseract.image_to_string(imagem, config='--oem 1 --psm 7').split('\\n')[0]\n","\n","def convert_bgr_to_grayscale(bgr_img: np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    Converts an image from BGR to grayscale using the equation:\n","    C[y, x] = 0.114 * B[y, x] + 0.587 * G[y, x] + 0.299 * R[y, x]\n","    :param bgr_img: matrix (H, W, 3) which represents an image with height H, width W, and 3 color channels as BGR.\n","    :return: a new image (H, W) in grayscale in the 8 bits format.\n","    Uses truncation when converting floats to uint8 (for autograding).\n","    \"\"\"\n","    gray_img = (bgr_img[:,:, 0]*0.114+bgr_img[:,:, 1]*0.587+bgr_img[:,:, 2]*0.299).astype(np.uint8)\n","    return gray_img\n","\n","# def gain(img: np.ndarray, alpha: float, beta: float) -> np.ndarray:\n","#     \"\"\"\n","#     This function implements an affine transform composed of additive and multiplicative gains following:\n","#     Ir[y, x] = alpha * I[y, x] + beta.\n","#     Moreover, the value is clipped to stay within the interval [0, 255].\n","#     :param img: matrix (H, W) or (H, W, C) which represents an image with height H, width W, and C color channels.\n","#     :param alpha: multiplicative gain.\n","#     :param beta: additive gain.\n","#     :return: the transformed image.\n","#     \"\"\"\n","#     output_img = np.clip(img.astype(np.float64) * alpha + beta,0,255).astype(np.uint8)\n","#     return output_img\n","\n","# def recover_dark_image(img: np.ndarray) -> np.ndarray:\n","#     \"\"\"\n","#     Apply a gain transform to recover a dark image of a container plane.\n","#     :param img: matrix (H, W) or (H, W, C) which represents an image of height H, width W, and C color channels.\n","#     :return: a recovered image, where it is possible to visualize the characters of the plate.\n","#     \"\"\"\n","#     return gain(img,10.0,180)\n","\n","def padding(image: np.ndarray, border_color: tuple, padding: tuple) -> np.ndarray:\n","    \"\"\"\n","    Add padding to an image.\n","    :param image: matrix (H, W, C) which represents an image of height H, width W, and C color channels.\n","    :param border_color: tuple (C1, C2, C3, ...) which represents a color that can be applied to a border.\n","    :param padding: tuple (left, right, top, bottom) which represents the amount of pixels to be added\n","                    to each border.\n","    :return: the image after padding.\n","    \"\"\"\n","    h0, w0, c = image.shape\n","    left, right, top, bottom = padding\n","    padded_image = np.zeros((h0 + top + bottom, w0 + left + right, c), dtype=np.uint8)\n","\n","    padded_image[top:top + h0, left:left + w0, :] = image\n","\n","    padded_image[:top, :, :] = border_color\n","    padded_image[top + h0:, :, :] = border_color\n","    padded_image[:, :left, :] = border_color\n","    padded_image[:, left + w0:, :] = border_color\n","\n","    return padded_image\n","\n","def plate_padding(image):\n","  \"\"\"\n","  Adds padding to a plate image so the OCR method can correctly identify the characters.\n","  :param image: matrix (H, W, 3) which represents an image of height H, width W, and 3 color channels.\n","  :return: an image where characters close to the borders are recognizable by the OCR method.\n","  \"\"\"\n","  return padding(image, (255, ), (4, 4, 4, 4))"],"metadata":{"id":"A9-hZL2gCWYQ"},"id":"A9-hZL2gCWYQ","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"d8fa8c6b","metadata":{"id":"d8fa8c6b"},"source":["# Dataset"]},{"cell_type":"code","source":["!rm -rf placas"],"metadata":{"id":"LDr7yZJsEEmo"},"id":"LDr7yZJsEEmo","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"6073c5d0","metadata":{"id":"6073c5d0"},"outputs":[],"source":["! [ ! -d \"/content/placas\" ] && gdown -O /content/placas.zip 1JC0d28kH--8TYTIfMhbbHvbI5NPWzsdr &&  unzip /content/placas.zip -d /content && rm /content/placas.zip\n","\n","imgs_path = Path(\"/content/placas\")"]},{"cell_type":"code","execution_count":null,"id":"048184ef","metadata":{"id":"048184ef"},"outputs":[],"source":["plate = cv2.cvtColor(cv2.imread(str(imgs_path/'placa_original.jpg')), cv2.COLOR_BGR2RGB)\n","print(ocr(plate))\n","PIL.Image.fromarray(plate)"]},{"cell_type":"markdown","source":["# Manipulações Vetoriais"],"metadata":{"id":"ihJhbt5_QSPw"},"id":"ihJhbt5_QSPw"},{"cell_type":"markdown","source":["## Grayscale"],"metadata":{"id":"WoGqyNZU0zR5"},"id":"WoGqyNZU0zR5"},{"cell_type":"code","execution_count":null,"id":"7d685157","metadata":{"id":"7d685157"},"outputs":[],"source":["img = cv2.imread(str(imgs_path/'picture.png'))\n","PIL.Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) # Pillow expects a RGB image"]},{"cell_type":"code","execution_count":null,"id":"b14a4395","metadata":{"id":"b14a4395"},"outputs":[],"source":["gray_img = convert_bgr_to_grayscale(img)\n","PIL.Image.fromarray(gray_img)"]},{"cell_type":"markdown","source":["## Padding"],"metadata":{"id":"r07Ugnsi04uI"},"id":"r07Ugnsi04uI"},{"cell_type":"code","source":["cropped_plate = cv2.imread(str(imgs_path/'placa_cortada.png'))\n","\n","print(ocr(cropped_plate))\n","PIL.Image.fromarray(cv2.cvtColor(cropped_plate, cv2.COLOR_BGR2RGB))"],"metadata":{"id":"aLVWqTfFPtJQ"},"id":"aLVWqTfFPtJQ","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"75899382","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"99f99c990f971f938e516aadfe9dc6e0","grade":true,"grade_id":"testa_recupera_borda","locked":true,"points":0.5,"schema_version":3,"solution":false,"task":false},"id":"75899382"},"outputs":[],"source":["padded_plate = plate_padding(cropped_plate)\n","\n","print(ocr(padded_plate))\n","PIL.Image.fromarray(padded_plate)"]},{"cell_type":"markdown","id":"e83d3bd2","metadata":{"id":"e83d3bd2"},"source":["## Correlação Cruzada e Convolução\n","\n","Vamos implementar correlação cruzada aqui. A diferença em relação a Concolução não é muito significativa, porque podemos realizar convolução usando correlação cruzada simplesmente invertendo o núcleo horizontal e verticalmente."]},{"cell_type":"code","execution_count":null,"id":"9a6846fe","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"f27f63f242dad199b5cdc8c5784eb86d","grade":false,"grade_id":"conv","locked":false,"schema_version":3,"solution":true,"task":false},"id":"9a6846fe"},"outputs":[],"source":["def cross_correlation(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    Executes cross correlation of an image using a filter (kernel or mask).\n","    :param image: matrix (H, W) which represents an image of height H and width W.\n","    :param kernel: matrix (Hf, Wf) which represents a filter (kernel or mask) of height Hf and width Wf.\n","    :return: the result of the cross correlation between the image and the filter.\n","    \"\"\"\n","    h0, w0 = image.shape\n","    hf, wf = kernel.shape\n","    output = np.zeros((h0 - hf + 1, w0 - wf + 1), dtype=np.float64)\n","    for i in range(h0 - hf + 1):\n","        for j in range(w0 - wf + 1):\n","            output[i, j] = np.sum(kernel*image[i:i + hf, j:j + wf])\n","    return output\n"]},{"cell_type":"code","execution_count":null,"id":"7167cb9c","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"6668c4a18126ef649203f1876dc44ba3","grade":true,"grade_id":"testa_conv","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"id":"7167cb9c"},"outputs":[],"source":["assert np.all(cross_correlation(\n","    np.array([[1, 1, 1, 0, 0],\n","              [0, 1, 1, 1, 0],\n","              [0, 0, 1, 1, 1],\n","              [0, 0, 1, 1, 0],\n","              [0, 1, 1, 0, 0]]),\n","    np.array([[1, 0, 1],\n","              [0, 1, 0],\n","              [1, 0, 1]])) == np.array([[4, 3, 4],\n","                                        [2, 4, 3],\n","                                        [2, 3, 4]]))"]},{"cell_type":"markdown","id":"2f69c291","metadata":{"id":"2f69c291"},"source":["Uma correlação cruzada com um determinado filtro (kernel) pode implementar uma operação matemática conhecida. Por exemplo, o filtro de Sobel implementa uma derivada parcial da imagem através da diferença finita. A correlação cruzada da imagem com o filtro de Sobel produz uma imagem que enfatiza os contornos verticais na imagem original. O filtro de Sobel para calcular a derivada parcial x da imagem é dado por:\n","\n","$\\mathbf {S} _{x}={\\begin{bmatrix}+1&0&-1\\\\+2&0&-2\\\\+1&0&-1\\end{bmatrix}}$\n","\n"]},{"cell_type":"code","source":["plt.figure(figsize=(9,9))\n","plt.axis(False)\n","plt.imshow(gray_img, cmap='gray')\n","plt.plot()"],"metadata":{"id":"wTM4df6DOse4"},"id":"wTM4df6DOse4","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"65760a3c","metadata":{"id":"65760a3c"},"outputs":[],"source":["sobel_x = np.array([[1, 0, -1],\n","                    [2, 0, -2],\n","                    [1, 0, -1]])\n","gray_img_dx = cross_correlation(gray_img, sobel_x)\n","plt.figure(figsize=(9,9))\n","plt.axis(False)\n","plt.imshow(gray_img_dx, cmap='gray')\n","plt.plot()"]},{"cell_type":"markdown","source":["## Convolução\n","\n","A implementação abaixo corresponde à operação matemática equivalente à convolução, pois o núcleo está invertido.\n","\n","Operação de correlação cruzada:\n","\n","$G[i, j] = \\sum^k_{u=-k} \\sum^k_{v=-k} H[u, v] I[i - u, j - v]$"],"metadata":{"id":"buzxA__E6yNy"},"id":"buzxA__E6yNy"},{"cell_type":"code","source":["def convolution(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    Executes convolution of an image using a filter (kernel or mask).\n","    :param image: matrix (H, W) which represents an image of height H and width W.\n","    :param kernel: matrix (Hf, Wf) which represents a filter (kernel or mask) of height Hf and width Wf.\n","    :return: the result of the convolution between the image and the filter.\n","    \"\"\"\n","    h0, w0 = image.shape\n","    hf, wf = kernel.shape\n","    output = np.zeros((h0 - hf + 1, w0 - wf + 1), dtype=np.float64)\n","    for i in range(h0 - hf + 1):\n","        for j in range(w0 - wf + 1):\n","            output[i, j] = np.sum(np.flip(kernel) * image[i:i + hf, j:j + wf])\n","    return output"],"metadata":{"id":"IOYSYmA67Ky9"},"id":"IOYSYmA67Ky9","execution_count":null,"outputs":[]},{"cell_type":"code","source":["sobel_x = np.array([[1, 0, -1],\n","                    [2, 0, -2],\n","                    [1, 0, -1]])\n","gray_img_cx = convolution(gray_img, sobel_x)\n","plt.figure(figsize=(9,9))\n","plt.axis(False)\n","plt.imshow(gray_img_cx, cmap='gray')\n","plt.plot()"],"metadata":{"id":"7A4dK5d-7hdC"},"id":"7A4dK5d-7hdC","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"571ab476","metadata":{"id":"571ab476"},"source":["## Filtro Gaussiano\n","\n","O filtro gaussiano é frequentemente usado para desfocar imagens ou atenuar ruídos. O kernel do filtro gaussiano é uma aproximação discreta da função gaussiana 2D:\n","\n","$H(x, j) = \\frac{1}{2 \\pi \\sigma^2} \\exp \\left( -\\frac{(x - x_0)^2 + (y - y_0)^2}{2 \\sigma^2} \\right)$.\n","\n","A aproximação discreta é calculada como:\n","\n","$H[u, v] = \\alpha  \\exp \\left( \\frac{-(u-u_0)^2 + (v-v_0)^2}{2 \\sigma^2} \\right)$,\n","\n","onde α é uma constante de normalização para que os valores do kernel somem 1 e σ é um parâmetro de design.\n","\n","Este é o melhor filtro clássico para atenuar ruído gaussiano. Também pode ser interpretado como um filtro passa-baixo que atenua altas frequências. Usando uma transformada de Fourier, podemos verificar que este filtro atenua altas frequências.\n"]},{"cell_type":"code","execution_count":null,"id":"27e7d0ef","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"1a39bd8bf954f416a281ef54bc9d5ae6","grade":false,"grade_id":"gauss","locked":false,"schema_version":3,"solution":true,"task":false},"id":"27e7d0ef"},"outputs":[],"source":["def build_gaussian_kernel(k, sigma):\n","    \"\"\"\n","    Builds a Gaussian kernel of size k and standard deviation sigma.\n","    :param k: kernel size.\n","    :param sigma: standard deviation.\n","    Retorna o kernel gaussiano normalizado, matriz float de tamanho (k, k) tipo float64\n","    \"\"\"\n","    kernel = np.zeros((k, k), dtype=np.float64)\n","\n","    u0 = v0 = (k - 1) / 2\n","\n","\n","    ##IMPLEMENTE A APROXIMAÇÃO DISCRETA\n","\n","    alpha = 1 / np.sum(kernel)\n","\n","    return alpha * kernel\n"]},{"cell_type":"code","source":["blurred_img = cross_correlation(gray_img, build_gaussian_kernel(7, 5))\n","plt.figure(figsize=(9,9))\n","plt.axis(False)\n","plt.imshow(blurred_img, cmap='gray')\n","plt.plot()"],"metadata":{"id":"lQlYcT1FAXM4"},"id":"lQlYcT1FAXM4","execution_count":null,"outputs":[]},{"cell_type":"code","source":["identity_kernel = np.zeros((5, 5))\n","identity_kernel[2, 2] = 1\n","sharpen_kernel = 4 * identity_kernel - 3 * np.ones((5, 5)) / (5 * 5)\n","print('Sharpen Kernel:')\n","print(sharpen_kernel)\n","sharpened_img = cross_correlation(blurred_img, sharpen_kernel)\n","plt.figure(figsize=(9,9))\n","plt.axis(False)\n","plt.imshow(sharpened_img, cmap='gray')\n","plt.plot()"],"metadata":{"id":"ZLBu20Oy_7Us"},"id":"ZLBu20Oy_7Us","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"6096e209","metadata":{"id":"6096e209"},"source":["## Noise\n","\n","O ruído gaussiano está relacionado especialmente à amostragem de fótons incidentes nos sensores de imagem e aos fótons espúrios provenientes da radiação corporal negra.\n","\n","O filtro clássico que melhor atenua o ruído gaussiano é o filtro gaussiano.\n","\n","Para cada pixel, uma variável aleatória seguindo uma distribuição gaussiana é adicionada ao valor do pixel:\n","\n","$I'[i,j] = I[i,j] + \\eta[i,j]$,\n","\n","Onde $\\eta[i,j] \\sim N(0,\\sigma^2)$.\n"]},{"cell_type":"code","execution_count":null,"id":"78103f21","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"6495f44003bbf84444134379395d0885","grade":false,"grade_id":"ruido","locked":false,"schema_version":3,"solution":true,"task":false},"id":"78103f21"},"outputs":[],"source":["def filter_noise_plate(image: np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    Applies a Gaussian filter in a plate's image so the OCR is able to identify the characters. Uses the cross correlation\n","    function with a Gaussian filter.\n","    :param image: matrix (H, W) which represents an image with height H and width W.\n","    :return: filtered image so the characters are  identifiable by the OCR.\n","    \"\"\"\n","    kernel = build_gaussian_kernel(3, 2)\n","\n","    #Execute a correlacao ou a convolucao\n","\n","    return filtered_img.astype(np.uint8)"]},{"cell_type":"code","execution_count":null,"id":"32469ef3","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"e8d8031c29168579f19d49cbe1bf00ba","grade":true,"grade_id":"testa_ruido","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"32469ef3"},"outputs":[],"source":["noisy_plate = convert_bgr_to_grayscale(cv2.imread(str(imgs_path/'placa_ruido.png')))\n","filtered_plate = filter_noise_plate(noisy_plate)\n","assert ocr(filtered_plate) == 'MEDU 297781 3'\n"]},{"cell_type":"code","execution_count":null,"id":"c89492e4","metadata":{"id":"c89492e4"},"outputs":[],"source":["print(ocr(noisy_plate))\n","PIL.Image.fromarray(noisy_plate)"]},{"cell_type":"code","execution_count":null,"id":"90f30f49","metadata":{"id":"90f30f49"},"outputs":[],"source":["print(ocr(filtered_plate))\n","PIL.Image.fromarray(filtered_plate)"]},{"cell_type":"markdown","id":"e0f108c1","metadata":{"id":"e0f108c1"},"source":["## Operações Morfológicas\n","\n","As operações morfológicas são semelhantes à correlação cruzada com um kernel, pois deslizamos uma janela pela imagem. No entanto, as operações são não lineares. Por exemplo, as operações morfológicas de dilatação e erosão escolhem o máximo e o mínimo da janela, respectivamente. Essas operações são implementadas no OpenCV por cv2.dilate e cv2.erode, respectivamente.\n","\n","![Dilatação](https://penny-xu.github.io/dialate-d6ec2fc1995eeeb95b917db2c6e1cea0.gif)\n","\n","As operações morfológicas são definidas para imagens binárias. No entanto, também podemos generalizá-las para tons de cinza (elemento máximo/mínimo de uma janela).\n","\n","Além disso, para binarizar a imagem de Lena abaixo, usamos um limiar de 120."]},{"cell_type":"code","execution_count":null,"id":"9e9118dd","metadata":{"id":"9e9118dd"},"outputs":[],"source":["binary_img = 255 * (gray_img > 120).astype(np.uint8)\n","PIL.Image.fromarray(binary_img)"]},{"cell_type":"code","execution_count":null,"id":"e7ca10aa","metadata":{"id":"e7ca10aa"},"outputs":[],"source":["structuring_element = np.ones((3, 3))\n","dillated_img = cv2.dilate(binary_img, structuring_element)\n","PIL.Image.fromarray(dillated_img)"]},{"cell_type":"code","execution_count":null,"id":"f54a4bb8","metadata":{"id":"f54a4bb8"},"outputs":[],"source":["structuring_element = np.ones((3, 3))\n","eroded_img = cv2.erode(binary_img, structuring_element)\n","PIL.Image.fromarray(eroded_img)"]},{"cell_type":"code","execution_count":null,"id":"722f423a","metadata":{"id":"722f423a"},"outputs":[],"source":["faint_plate = convert_bgr_to_grayscale(cv2.imread(str(imgs_path/'placa_erodida.png')))\n","print(ocr(faint_plate))\n","PIL.Image.fromarray(faint_plate)"]},{"cell_type":"code","execution_count":null,"id":"e0bfcd17","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"8ee0c80bd539306ee56f7b806e6456f6","grade":false,"grade_id":"dilatacao","locked":false,"schema_version":3,"solution":true,"task":false},"id":"e0bfcd17"},"outputs":[],"source":["def morphological_operation_plate(image: np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    Executes a morphological operation to recover the plate.\n","    :param image: matrix (H, W) which represents an image of height H and width W.\n","    :return: image after morphological operation that allows the identification of the characters through OCR.\n","    \"\"\"\n","    structuring_element = np.ones((3, 3))\n","\n","    output = cross_correlation(image, structuring_element)\n","    return output.astype(np.uint8)"]},{"cell_type":"code","execution_count":null,"id":"69b00334","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"0a8e541fd5fd5dd958b253fb9e93ae8f","grade":true,"grade_id":"testa_dilatacao","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"69b00334"},"outputs":[],"source":["faint_plate = convert_bgr_to_grayscale(cv2.imread(str(imgs_path/'placa_erodida.png')))\n","recovered_plate = morphological_operation_plate(faint_plate)\n","print(ocr(recovered_plate))\n","PIL.Image.fromarray(recovered_plate)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}